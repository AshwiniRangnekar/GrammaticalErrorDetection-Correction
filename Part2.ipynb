{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the train data from file and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Reading the train.txt file into raw_data '''\n",
    "\n",
    "raw_data = []                                              # Can be used for further processing\n",
    "unigram = {}\n",
    "error_dictionary = {}\n",
    "sentences_list = []\n",
    "filename = \"/home/ashwini/Dropbox/Sem3/NLP/P1B/Data/train.txt\"\n",
    "file = open(filename, \"r\")\n",
    "for line in file.readlines():\n",
    "    line = line.split('\\n')\n",
    "    raw_data.append(line[0])\n",
    "file.close()\n",
    "\n",
    "# Dictionary to maintain the mapping of errors\n",
    "map_errtoint = {'Nn':1,'Cit':2,'Rloc-':3,'Mec':4,'ArtOrDet':5,'Vform':6,'V0':7,'SVA':8,'Others':9,'Vt':10,'Wform':11,'Pform':12,'Wci':13,'Trans':14,'Sfrag':15,'Um':16,'Prep':17,'Pref':18,'Spar':19,'WOinc':20,'Wtone':21,'Vm':22,'WOadv':23,'Srun':24,'Npos':25,'Wa':26,'Smod':27,'Ssub':28,'Noerror':29}\n",
    "map_inttoerr = {value: key for key, value in map_errtoint.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "incorrect_sentences_list = []\n",
    "correct_sentences_list = []\n",
    "\n",
    "str_correct = \"\"\n",
    "str_incorrect = \"\"\n",
    "str_error = \"\"\n",
    "\n",
    "error_sentences_list = []\n",
    "l = []\n",
    "\n",
    "trigram_freq = {}\n",
    "correction = {}\n",
    "process_data = []\n",
    "\n",
    "start_of_sent = \"<S>\"\n",
    "end_of_sent = \"<E>\"\n",
    "process_data.append(start_of_sent)\n",
    "\n",
    "for i in range(0,len(raw_data)):\n",
    "    if raw_data[i] == '':\n",
    "        continue\n",
    "    elif raw_data[i]==\".\":\n",
    "        process_data.append(end_of_sent)\n",
    "        process_data.append(start_of_sent)\n",
    "        i +=1\n",
    "    else:\n",
    "        process_data.append(raw_data[i]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Main Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the main data structure : Dictionary which will store the errorneous trigram along with its \n",
    "frequency and corrected triagram for each Error class \n",
    "'''\n",
    "# Creating triagrams from the raw data given to us\n",
    "pre2 = process_data[1]\n",
    "pre1 = process_data[2]\n",
    "i = 3\n",
    "\n",
    "while i<len(process_data):\n",
    "    curr = process_data[i]\n",
    "    \n",
    "    if curr == \"<E>\":                   # Skip the end of the sentence tag from getting into the triagram\n",
    "        pre2 = process_data[i+2]\n",
    "        pre1 = process_data[i+3]\n",
    "        i += 4\n",
    "        continue\n",
    "    \n",
    "    corr_tri = []\n",
    "    incorr_tri = []\n",
    "    error = []\n",
    "    word_error = []\n",
    "    \n",
    "    if(pre2.count('   ') == 2):\n",
    "        temp = pre2.split('   ')\n",
    "        incorr_tri.append(str(temp[0]))\n",
    "        corr_tri.append(temp[1])\n",
    "        error.append(temp[2])\n",
    "        word_error.append(temp[2])\n",
    "    else:\n",
    "        incorr_tri.append(pre2)\n",
    "        corr_tri.append(pre2)\n",
    "        word_error.append('')\n",
    "        \n",
    "    \n",
    "    if(pre1.count('   ') == 2):\n",
    "        temp = pre1.split('   ')\n",
    "        incorr_tri.append(str(temp[0]))\n",
    "        \n",
    "        if temp[1] in corr_tri:\n",
    "            corr_tri.append('')\n",
    "        else:\n",
    "            corr_tri.append(temp[1])\n",
    "        \n",
    "        error.append(temp[2])\n",
    "        word_error.append(temp[2])\n",
    "    else:\n",
    "        incorr_tri.append(pre1)\n",
    "        corr_tri.append(pre1)\n",
    "        word_error.append('')\n",
    "        \n",
    "    \n",
    "    if(curr.count('   ') == 2):\n",
    "        temp = curr.split('   ')\n",
    "        incorr_tri.append(str(temp[0]))\n",
    "        \n",
    "        if temp[1] in corr_tri:\n",
    "            corr_tri.append('')\n",
    "        else:\n",
    "            corr_tri.append(temp[1])\n",
    "        \n",
    "        error.append(temp[2])\n",
    "        word_error.append(temp[2])\n",
    "    else:\n",
    "        incorr_tri.append(curr)\n",
    "        corr_tri.append(curr)\n",
    "        word_error.append('')\n",
    "    \n",
    "    pre2 = pre1\n",
    "    pre1 = curr\n",
    "    i += 1\n",
    "    \n",
    "    error = set(error)\n",
    "    tup_incorr = tuple(incorr_tri)\n",
    "    # print(tup_incorr)\n",
    "    tup_corr = tuple(corr_tri)\n",
    "    # print(tup_corr)\n",
    "    tup_word_error = tuple(word_error)\n",
    "    # print(tup_word_error)\n",
    "    \n",
    "    if(len(error)==0):\n",
    "        num = 29\n",
    "        if num not in trigram_freq:\n",
    "            temp_dict ={}\n",
    "            temp_dict[tup_incorr] = (1,tup_corr,tup_word_error)\n",
    "            trigram_freq[num] = temp_dict\n",
    "\n",
    "        else:\n",
    "            temp_dict = {}\n",
    "            temp_dict = trigram_freq[num]\n",
    "            if tup_incorr not in temp_dict:\n",
    "                trigram_freq[num].update({tup_incorr:(1,tup_corr,tup_word_error)})\n",
    "\n",
    "            else:\n",
    "                val = temp_dict[tup_incorr]\n",
    "                v = val[0] + 1\n",
    "                temp_dict[tup_incorr] = (v,tup_corr,tup_word_error)\n",
    "                \n",
    "    else:\n",
    "        for j in error:\n",
    "            num = map_errtoint.get(j,-1)\n",
    "            \n",
    "            if num not in trigram_freq:\n",
    "                # print(num)\n",
    "                temp_dict ={}\n",
    "                temp_dict[tup_incorr] = (1,tup_corr,tup_word_error)\n",
    "                trigram_freq[num] = temp_dict\n",
    "\n",
    "            else:\n",
    "                temp_dict = {}\n",
    "                temp_dict = trigram_freq[num]\n",
    "                if tup_incorr not in temp_dict:\n",
    "                    trigram_freq[num].update({tup_incorr:(1,tup_corr,tup_word_error)})\n",
    "\n",
    "                else:\n",
    "                    val = temp_dict[tup_incorr]\n",
    "                    v = val[0] + 1\n",
    "                    temp_dict[tup_incorr] = (v,tup_corr,tup_word_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintaining count of triagrams in each error class and the number of total triagrams seen in the complete dataset   \n",
    "\n",
    "size_dict = {}\n",
    "Total_trigrams = 0\n",
    "for key,value in trigram_freq.items():\n",
    "    for k,v in trigram_freq[key].items():\n",
    "        size_dict[key] = size_dict.get(key,0) + v[0]\n",
    "    Total_trigrams += size_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Good Turing for Smoothing : Handling unseen triagrams ''' \n",
    "\n",
    "# Invert the dictionary to maintain freq-of-freq \n",
    "def eq_classes(tm):\n",
    "    eq = {}\n",
    "    for k, v in tm.items():\n",
    "        if v not in eq:\n",
    "            eq[v[0]] = []\n",
    "        eq[v[0]].append(k)\n",
    "    return eq\n",
    "\n",
    "def good_turing_smoothing(tm,N):\n",
    "    Nr = eq_classes(tm)\n",
    "    \n",
    "    nr_counts = {k : len(v) for k, v in Nr.items()}\n",
    "    nr_probs = {k : (k*v)/float(N) for k, v in nr_counts.items()}\n",
    "    \n",
    "    sorted_nrs = sorted(nr_counts.items())\n",
    "    sorted_probs = sorted(nr_probs.items())\n",
    "    MAX = sorted_nrs[0][1]\n",
    "    \n",
    "    new_nrs = {}\n",
    "    for r, nr in Nr.items():\n",
    "        if (r+1) in Nr:\n",
    "            new_nr = ((r+1) * len(Nr[r+1])) / float(N) \n",
    "        else:\n",
    "            new_nr = MAX*r**-2 / float(N)\n",
    "        new_nrs[r] = new_nr\n",
    "        \n",
    "    return new_nrs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting error for a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"the life expectancy of individuals has increased due to better accessibility to healthcare services and facilities than before\"\n",
    "# #sent = \"governments all around the world has to make provision for improved healthcare as - live expectancy of their citizens and medical technological advancement are improving by the years.\"\n",
    "# sent = sent.split(\" \")\n",
    "# pre2 = sent[0]\n",
    "# pre1 = sent[1]\n",
    "\n",
    "# for i in range(2,len(sent)):\n",
    "#     curr = sent[i]\n",
    "#     trigram = (pre2,pre1,curr)\n",
    "#     error_class = -1\n",
    "#     prob = -10.00 \n",
    "    \n",
    "#     for num in range(1,30):\n",
    "#         temp_dict = {}\n",
    "#         temp_dict = trigram_freq[num]\n",
    "#         val = temp_dict.get(trigram,())\n",
    "        \n",
    "#         if len(val) != 0:\n",
    "#             v = float(val[0])/ float(size_dict[num])\n",
    "#             print(str(trigram) + \"   \" + map_inttoerr[num] + \"    \" + str(v)),\n",
    "#             if prob<v:\n",
    "#                 error_class = num\n",
    "#                 prob = v\n",
    "#         else:\n",
    "#             v = good_turing_smoothing(trigram_freq[num],Total_trigrams)\n",
    "#             if prob<v:\n",
    "#                 error_class = num\n",
    "#                 prob = v\n",
    "    \n",
    "    \n",
    "#     if(error_class != 29 and error_class != -1):\n",
    "#         print(error_class)\n",
    "#         print(str(trigram) + \"   \" + map_inttoerr[error_class] + \"    \" + str(prob))\n",
    "\n",
    "#     pre2 = pre1\n",
    "#     pre1 = curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on given test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read Test File '''\n",
    "\n",
    "filepath1 = \"/home/ashwini/Dropbox/Sem3/NLP/P1B/Data/dev.txt\"\n",
    "file1 = open(filepath1,'r')\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for lines in file1.readlines():\n",
    "    lines = lines.split('\\n')\n",
    "    test_data.append(lines[0])\n",
    "    \n",
    "file1.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the given test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generate trigrams for test data '''\n",
    "\n",
    "trigram_freq_testdata = []\n",
    "process_testdata = []\n",
    "\n",
    "start_of_sent = \"<S>\"\n",
    "end_of_sent = \"<E>\"\n",
    "process_testdata.append(start_of_sent)\n",
    "\n",
    "for i in range(0,len(test_data)):\n",
    "    # print(i)\n",
    "    if test_data[i] == '':\n",
    "        continue\n",
    "    elif test_data[i]==\".\":\n",
    "        process_testdata.append(end_of_sent)\n",
    "        process_testdata.append(start_of_sent)\n",
    "        i +=1\n",
    "    else:\n",
    "        ss = test_data[i].split(\"   \")\n",
    "        process_testdata.append(ss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating triagram for the test data and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre2 = process_testdata[1]\n",
    "pre1 = process_testdata[2]\n",
    "i = 3\n",
    "output = []\n",
    "output1 = []\n",
    "while i in range(0,len(process_testdata)):\n",
    "    curr = process_testdata[i]\n",
    "    if curr == \"<E>\":\n",
    "        if i+2 < len(process_testdata):\n",
    "            pre2 = process_testdata[i+2]\n",
    "            pre1 = process_testdata[i+3]\n",
    "            i += 4\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    trigram = (pre2,pre1,curr)\n",
    "#     print(trigram)\n",
    "    trigram_freq_testdata.append(trigram)\n",
    "    \n",
    "    pre2 = pre1\n",
    "    pre1 = curr\n",
    "    i += 1\n",
    "    \n",
    "    error_class = -1\n",
    "    prob = -10.00 \n",
    "    incorr_word = []\n",
    "    corr_word = []\n",
    "    \n",
    "    for num in range(1,30):\n",
    "        temp_dict = {}\n",
    "        temp_dict = trigram_freq[num]\n",
    "        val = temp_dict.get(trigram,())\n",
    "        \n",
    "        if len(val) != 0:\n",
    "            # Naive Bayes formula implemented here\n",
    "            v = float(val[0])/ float(size_dict[num])\n",
    "            v *= float(size_dict[num]) / float(Total_trigrams)\n",
    "            # As values were too small so every value is multiplied by same number\n",
    "            v *= 100000\n",
    "            if prob<v:\n",
    "                error_class = num\n",
    "                prob = v\n",
    "                \n",
    "                incorr_word.clear()\n",
    "                corr_word.clear()\n",
    "                \n",
    "                temp_list = val[2]\n",
    "                corr_word = list(val[1])\n",
    "                \n",
    "                for it in range(0,len(temp_list)):\n",
    "                    if temp_list[it] == map_inttoerr[num]:\n",
    "                        incorr_word.append(trigram[it])\n",
    "                    \n",
    "#If the trigram is not present in seen triagrams of dataset then smoothing is applied to handle such situation                       \n",
    "        else:\n",
    "#             v = good_turing_smoothing(trigram_freq[num],Total_trigrams)\n",
    "#             if prob<v:\n",
    "#                 error_class = num\n",
    "#                 prob = v\n",
    "            pass\n",
    "\n",
    "    # Identifying the words with error in triagram and then finding the corresponding error and correction\n",
    "    sss = \"\"\n",
    "    sss1 = \"\"\n",
    "    if(error_class != -1 and error_class != 29):\n",
    "        for t in trigram:\n",
    "            sss = \"\"\n",
    "            sss1 = \"\"\n",
    "            if t in incorr_word:\n",
    "                index = trigram.index(t)\n",
    "                correction = corr_word[index]\n",
    "                sss = t + \"   \" + correction +\"   \" + map_inttoerr[error_class]\n",
    "                sss1 = t + \"   \" + map_inttoerr[error_class]\n",
    "#                 print(sss)\n",
    "            else:\n",
    "                sss = t\n",
    "                sss1 = t\n",
    "                 \n",
    "            if len(output)>2:\n",
    "                if len(sss.split(\"   \")) == 3 and sss.split(\"   \")[0] == output[-1]:\n",
    "                    output[-1] = sss\n",
    "                    output1[-1] = sss1\n",
    "                    continue\n",
    "                if len(sss.split(\"   \")) == 3 and sss.split(\"   \")[0] == output[-2]:\n",
    "                    output[-2] = sss\n",
    "                    output1[-2] = sss1\n",
    "                    continue\n",
    "                elif sss != output[-1] and sss != output[-2]:\n",
    "                    output.append(sss)\n",
    "                    output1.append(sss1)\n",
    "            else:\n",
    "                output.append(sss)\n",
    "                output1.append(sss1)\n",
    "            \n",
    "    # Handling repeated entries while inserting in output file dev-results    \n",
    "    else:\n",
    "        for t in trigram:\n",
    "            if len(output)>=3:\n",
    "                # print(output[-1] + \" \" + output[-2])\n",
    "                if (len(output[-1].split(\"   \")) == 1 and t == output[-1]) or (len(output[-2].split(\"   \")) == 1 and t == output[-2]):\n",
    "                    continue\n",
    "                if (len(output[-1].split(\"   \")) == 3 and t == output[-1].split(\"   \")[0]) or (len(output[-2].split(\"   \")) == 3 and t == output[-2].split(\"   \")[0]):\n",
    "                    continue\n",
    "                if (len(output[-3].split(\"   \")) == 3 and t == output[-3].split(\"   \")[0]) or (len(output[-3].split(\"   \")) == 1 and t == output[-3]):\n",
    "                    continue\n",
    "                else:                \n",
    "                    output.append(t)\n",
    "                    output1.append(t)\n",
    "            else:\n",
    "                output.append(t)\n",
    "                output1.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing in output file\n",
    "'''\n",
    "file_output = open(\"/home/ashwini/Dropbox/Sem3/NLP/P1B/Data/dev_correction_result.txt\",\"w+\")\n",
    "for ii in output:\n",
    "#     print(ii)\n",
    "    file_output.write(ii+\"\\n\")  \n",
    "\n",
    "file_output.close()\n",
    "\n",
    "# file_output = open(\"/home/ashwini/Dropbox/Sem 3/NLP/P1B/Data/dev_result.txt\",\"w+\")\n",
    "# for ii in output1:\n",
    "# #     print(ii)\n",
    "#     file_output.write(ii+\"\\n\")  \n",
    "\n",
    "# file_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
